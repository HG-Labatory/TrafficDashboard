# Verkehrs-Dashboard

## Ãœberblick

Dieses Projekt ist ein **statisches Verkehrs-Dashboard**, das aktuelle Verkehrsmeldungen sammelt, strukturiert speichert und als **statische Webseite** bereitstellt.
Der Fokus liegt auf **ZuverlÃ¤ssigkeit**, **Einfachheit** und **kontrollierter Aktualisierung** ohne dauerhaft laufendes Backend.

Die Anwendung richtet sich an die **Allgemeinheit** und stellt Informationen aus der Verkehrswelt Ã¼bersichtlich dar (z.â€¯B. Verkehrsmeldungen, perspektivisch Verkehrsprojekte und Verkehrswissenschaft).

---

## Grundidee

Statt einer klassischen Webanwendung mit dauerhaft laufendem Server folgt das Projekt einem **Build-Time-Ansatz**:

* Daten werden **periodisch gesammelt** (Scraper)
* strukturiert in einer **Datenbank** gespeichert
* **beim Deploy** aus der Datenbank in **JSON-Dateien exportiert**
* die Webseite liest **nur statische JSON-Daten** (GitHub Pages)

ðŸ‘‰ Kein Backend-Server, keine API zur Laufzeit, keine offenen Ports.

---

## Architektur

```
RSS / Webseiten
        â†“
Python Scraper (run_all.py)
        â†“
PostgreSQL Datenbank (traffic_items)
        â†“
Export-Skript (export_data.py)
        â†“
JSON-Dateien (docs/data/news.json)
        â†“
Statische Webseite (GitHub Pages)
```

### Architekturprinzip

> **Die Datenbank ist die interne Quelle der Wahrheit.**
> **Die Webseite konsumiert ausschlieÃŸlich statische Export-Artefakte.**

---

## Komponenten

### 1. Scraper

* Implementiert in Python
* Nutzt RSS-Feeds und ggf. strukturierte Webseiten
* Erkennt Duplikate (z.â€¯B. Ã¼ber `url`)
* Schreibt neue oder aktualisierte EintrÃ¤ge in die Datenbank

Beispielhafte Aufgaben:

* Verkehrsmeldungen sammeln
* Quellen vereinheitlichen
* Daten normalisieren

### 2. Datenbank (PostgreSQL)

Die Datenbank dient **nur der internen Verarbeitung**:

* Tabelle `traffic_items`
* saubere Struktur (Titel, Zusammenfassung, Region, URL, Datum)
* ermÃ¶glicht spÃ¤tere Erweiterungen (Filter, Projekte, Wissenschaft)

Die Datenbank wird **nicht direkt von der Webseite angesprochen**.

### 3. Export-Skript

* LÃ¤uft **manuell oder automatisiert beim Deploy**
* Liest Daten aus der Datenbank
* Erzeugt JSON-Dateien fÃ¼r die Webseite

Beispiel:

* `docs/data/news.json`

Damit ersetzt das Export-Skript vollstÃ¤ndig eine klassische API.

### 4. Statische Webseite

* Reines HTML, CSS und JavaScript
* Gehostet Ã¼ber GitHub Pages
* LÃ¤dt Daten Ã¼ber `fetch()` aus JSON-Dateien
* Keine dynamischen Server-Abfragen

Die Webseite ist dadurch:

* schnell
* kostengÃ¼nstig
* stabil
* leicht wartbar

---

## Projektstruktur

```
traffic-dashboard/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ db.py
â”‚   â””â”€â”€ models.py
â”‚
â”œâ”€â”€ scraper/
â”‚   â”œâ”€â”€ run_all.py        # Scraper â†’ Datenbank
â”‚   â””â”€â”€ export_data.py   # Datenbank â†’ JSON
â”‚
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ index.html
â”‚   â”œâ”€â”€ app.js
â”‚   â”œâ”€â”€ style.css
â”‚   â””â”€â”€ data/
â”‚       â””â”€â”€ news.json    # generiert
â”‚
â””â”€â”€ README.md
```

---

## Deploy-Workflow

Ein typischer Aktualisierungs- und Deploy-Ablauf:

```bash
1. Neue Daten sammeln

python -m scraper.run_all  

2. DB â†’ JSON exportieren 

python -m scraper/export_data

# 3. Ã„nderungen deployen
git add docs/data/news.json
git commit -m "Update traffic data"
git push
```

GitHub Pages Ã¼bernimmt anschlieÃŸend automatisch das Deployment der statischen Webseite.

---

## Warum diese Architektur?

### Vorteile

* âœ… Keine Serverkosten
* âœ… Kein dauerhaft laufendes Backend
* âœ… Klare Trennung von Datensammlung und Darstellung
* âœ… Hohe StabilitÃ¤t
* âœ… Gut erweiterbar

### Bewusste Entscheidungen

* **Datenbank**: fÃ¼r saubere Datenhaltung und Erweiterbarkeit
* **Kein FastAPI**: da keine Laufzeit-API benÃ¶tigt wird
* **Statische Webseite**: maximale Einfachheit beim Hosting
* **JSON als Austauschformat**: leichtgewichtig und browserfreundlich

---

## ErweiterungsmÃ¶glichkeiten

* zusÃ¤tzliche Kategorien (Verkehrsprojekte, Wissenschaft)
* mehrere JSON-Exports
* automatische Updates per GitHub Actions
* Filter und Sortierung im Frontend
* spÃ¤terer Ãœbergang zu einer API bei Bedarf

---

## Fazit

Dieses Projekt zeigt, wie man mit einfachen Mitteln ein **robustes, wartungsarmes Verkehrs-Dashboard** umsetzen kann:

* **Scraper + Datenbank** fÃ¼r QualitÃ¤t
* **Build-Time-Export** fÃ¼r Kontrolle
* **Statische Webseite** fÃ¼r ZuverlÃ¤ssigkeit

Eine bewusste Architekturentscheidung zugunsten von Klarheit statt KomplexitÃ¤t.
